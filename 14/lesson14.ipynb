{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lesson_14 聚类与分类\n",
    "\n",
    "## 聚类与分类的区别\n",
    "\n",
    " - 聚类: 无监督学习\n",
    "     - 一种分组观察的方法；分类时无任何参考就进行分类；无法简单地判别分类效果的好坏，分成2类或者3类的结果截然不同\n",
    "     - 主要用于探索未知的数据，进行数据的初步分类，主要是为了筛选出合适的分组，使得每一组里的数据相似度最大\n",
    "     - 判断聚类的效果，要基于业务实际情况\n",
    " - 分类：有监督学习\n",
    "     - 分类是有依据，类别是已经确定的\n",
    " \n",
    " \n",
    "![image](https://user-images.githubusercontent.com/26344632/41704645-6449032c-7569-11e8-9878-588188da80da.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 凝聚的层次聚类法 \n",
    "\n",
    "### 自下而上的聚类方法\n",
    "1. 开始时，每个样本各自作为一类\n",
    "2. 规定某种度量作为样本之间的距离及类与类之间的距离，并计算之\n",
    "3. 将距离最短的两个类合并为一个新类\n",
    "4. 重复2-3，即不断合并最近的两个类，每次减少一个类，直至所有样本被合并为一类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类与类之间距离计算的方法\n",
    "\n",
    " - 离差平方和法——ward：计算两个类别之间的离差平方和\n",
    "     - 离差平方和（Sum of Squares of Deviations）是各项与平均项之差的平方的总和。\n",
    "     - 定义是设x是一个随机变量，令η=x-Ex, 则 称 η为x的离差，它反映了x与其数学期望Ex的偏离程度。\n",
    " \n",
    " - 类平均法——average\n",
    "     - 类平均法（Average Linkage）中,用两类样品中,所有观测值两两观测间距离的平均作为类间距离.\n",
    " -  最大距离法——complete\n",
    "     - 计算两个类别之间的最大距离，使其最小化\n",
    "     \n",
    "### 观测点（样本点）的关键度量指标-距离\n",
    "![image](https://user-images.githubusercontent.com/26344632/41704614-4e5d3f9c-7569-11e8-98dc-035024a837aa.png)\n",
    "\n",
    "余弦距离：计算变量之间的聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如何计算层次聚类法\n",
    "\n",
    "1. 先构建一个聚类对象（模型）AgglomerativeClustering\n",
    "```\n",
    "AgglomerativeClustering(n_clusters=2, #聚成几类\n",
    "                        affinity='euclidean', # 点与点之间用哪种距离计算，默认欧式距离\n",
    "                        memory=Memory(cachedir=None), \n",
    "                        connectivity=None, \n",
    "                        n_components=None,\n",
    "                        compute_full_tree='auto', \n",
    "                        linkage='ward', # 类与类之间用哪种方式测距\n",
    "                        pooling_func=<function mean>)\n",
    "```\n",
    " -  属性\n",
    "    - labels # 样本点的标签\n",
    "    - n-leaves # 有几个层次（因为是一个层次聚类法)\n",
    "    - n-components # 有几个输出\n",
    "    - children # 非叶节点的子节点\n",
    " -  方法\n",
    "    - fit # 拟合\n",
    "    - fit_predict # 预测\n",
    "    - get_params\n",
    "    – set_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import manifold, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=10)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "print X[:5,:]\n",
    "print n_samples,n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clustering\n",
    "def plot_clustering(X_red, X, labels, title=None):\n",
    "    x_min, x_max = np.min(X_red, axis=0), np.max(X_red, axis=0)\n",
    "    X_red = (X_red - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for i in range(X_red.shape[0]):\n",
    "        plt.text(X_red[i, 0], X_red[i, 1], str(y[i]),\n",
    "                 color=plt.cm.spectral(labels[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title, size=17)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D embedding of the digits dataset\n",
    "print(\"Computing embedding\")\n",
    "X_red = manifold.SpectralEmbedding(n_components=2).fit_transform(X)\n",
    "print(\"Done.\")\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "for linkage in ('ward', 'average', 'complete'):\n",
    "    clustering = AgglomerativeClustering(linkage=linkage, n_clusters=10)\n",
    "    clustering.fit(X_red)\n",
    "    plot_clustering(X_red, X, clustering.labels_, \"%s linkage\" % linkage)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic(u'matplotlib inline')\n",
    "X0 = np.array([7, 5, 7, 3, 4, 1, 0, 2, 8, 6, 5, 3])\n",
    "X1 = np.array([5, 7, 7, 3, 6, 4, 0, 2, 7, 8, 5, 7])\n",
    "plt.figure()\n",
    "plt.axis([-1, 9, -1, 9])\n",
    "plt.grid(True)\n",
    "plt.plot(X0, X1, 'k.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = [1, 4, 5, 9, 11]\n",
    "C2 = list(set(range(12)) - set(C1))\n",
    "X0C1, X1C1 = X0[C1], X1[C1]\n",
    "X0C2, X1C2 = X0[C2], X1[C2]\n",
    "plt.figure()\n",
    "plt.axis([-1, 9, -1, 9])\n",
    "plt.grid(True)\n",
    "plt.plot(X0C1, X1C1, 'rx')\n",
    "plt.plot(X0C2, X1C2, 'g.')\n",
    "plt.plot(4,6,'rx',ms=12.0)\n",
    "plt.plot(5,5,'g.',ms=12.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = [1, 2, 4, 8, 9, 11]\n",
    "C2 = list(set(range(12)) - set(C1))\n",
    "X0C1, X1C1 = X0[C1], X1[C1]\n",
    "X0C2, X1C2 = X0[C2], X1[C2]\n",
    "plt.figure()\n",
    "plt.axis([-1, 9, -1, 9])\n",
    "plt.grid(True)\n",
    "plt.plot(X0C1, X1C1, 'rx')\n",
    "plt.plot(X0C2, X1C2, 'g.')\n",
    "plt.plot(3.8,6.4,'rx',ms=12.0)\n",
    "plt.plot(4.57,4.14,'g.',ms=12.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = [0, 1, 2, 4, 8, 9, 10, 11]\n",
    "C2 = list(set(range(12)) - set(C1))\n",
    "X0C1, X1C1 = X0[C1], X1[C1]\n",
    "X0C2, X1C2 = X0[C2], X1[C2]\n",
    "plt.figure()\n",
    "plt.axis([-1, 9, -1, 9])\n",
    "plt.grid(True)\n",
    "plt.plot(X0C1, X1C1, 'rx')\n",
    "plt.plot(X0C2, X1C2, 'g.')\n",
    "plt.plot(5.5,7.0,'rx',ms=12.0)\n",
    "plt.plot(2.2,2.8,'g.',ms=12.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = np.random.uniform(0.5, 1.5, (2, 10))\n",
    "cluster2 = np.random.uniform(3.5, 4.5, (2, 10))\n",
    "X = np.hstack((cluster1, cluster2)).T\n",
    "plt.figure()\n",
    "plt.axis([0, 5, 0, 5])\n",
    "plt.grid(True)\n",
    "plt.plot(X[:,0],X[:,1],'k.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "K = range(1, 10)\n",
    "meandistortions = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    meandistortions.append(sum(np.min(cdist(X, kmeans.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "plt.plot(K, meandistortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('The average degree of distortion')\n",
    "plt.title('Best k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1 = np.array([1, 2, 3, 1, 5, 6, 5, 5, 6, 7, 8, 9, 7, 9])\n",
    "x2 = np.array([1, 3, 2, 2, 8, 6, 7, 6, 7, 1, 2, 1, 1, 3])\n",
    "X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)\n",
    "plt.figure()\n",
    "plt.axis([0, 10, 0, 10])\n",
    "plt.grid(True)\n",
    "plt.plot(X[:,0],X[:,1],'k.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "K = range(1, 10)\n",
    "meandistortions = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    meandistortions.append(sum(np.min(cdist(X, kmeans.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "plt.plot(K, meandistortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('The average degree of distortion')\n",
    "plt.title('Best K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===================================\n",
    "Demo of DBSCAN clustering algorithm\n",
    "===================================\n",
    "\n",
    "Finds core samples of high density and expands clusters from them.\n",
    "\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Generate sample data\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "##############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
